# ğŸš€ AI Hallucination Guard â€” Archestra Multiâ€‘Agent System

## ğŸ“Œ Project Overview

AI Hallucination Guard is a multiâ€‘agent verification system built on **Archestra AI** that detects hallucinations in LLM responses. The system first generates a normal AI answer and then runs a verification agent that scores factual accuracy, risk level, and confidence.

This project was built for a hackathon to demonstrate:

* âœ… Multiâ€‘agent orchestration
* âœ… Groq LLM integration
* âœ… Realâ€‘time hallucination detection
* âœ… MCPâ€‘style tool pipeline
* âœ… Endâ€‘toâ€‘end local deployment

---

# ğŸ¯ Problem Statement

Large Language Models often produce confident but incorrect answers (hallucinations). Users have no builtâ€‘in way to verify factual correctness in real time.

**Goal:** Build a system that automatically verifies AI responses and flags hallucinations with measurable scores.

---

# ğŸ’¡ Solution Architecture

## ğŸ”„ Highâ€‘Level Flow

User â†’ Chat Assistant â†’ LLM Answer â†’ Hallucination Guard â†’ Score â†’ Final Output

### Agents Used

1. **Chatà·Š Chat Assistant (Main Agent)**

   * Generates primary AI response
   * Routes output for verification

2. **ğŸ›¡ï¸ Hallucination Guard (Subâ€‘Agent)**

   * Verifies factual accuracy
   * Calculates confidence score
   * Assigns risk level
   * Flags hallucinations

---

# ğŸ§° Tech Stack

* Archestra AI Platform
* Groq LLM (OpenAIâ€‘compatible endpoint)
* Node.js
* Docker & Docker Compose
* PostgreSQL
* Next.js (Archestra frontend)
* MCP architecture

---

# âš™ï¸ Local Setup Instructions

## âœ… Prerequisites (IMPORTANT)

Install the following on your machine:

### 1. Install Node.js

Download and install:
ğŸ‘‰ [https://nodejs.org](https://nodejs.org)

Verify:

```bash
node -v
npm -v
```

---

### 2. Install pnpm

```bash
npm install -g pnpm
```

Verify:

```bash
pnpm -v
```

---

### 3. Install Docker Desktop

Download:
ğŸ‘‰ [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)

After install:

* Start Docker Desktop
* Ensure it is running

Verify:

```bash
docker --version
docker compose version
```

---

### 4. Get Groq API Key

Go to:
ğŸ‘‰ [https://console.groq.com/keys](https://console.groq.com/keys)

Copy your key (starts with `gsk_...`)

---

# ğŸ“¥ Clone the Repository

Your teammate should run:

```bash
git clone https://github.com/YOUR_USERNAME/ai-hallucination-guard.git
cd ai-hallucination-guard
```

---

# ğŸ” Environment Setup

## Step 1: Create .env file

Inside:

```
archestra/platform/.env
```

Add these **critical lines at the bottom**:

```env
ARCHESTRA_QUICKSTART=false

OPENAI_API_KEY=gsk_your_actual_groq_key
OPENAI_BASE_URL=https://api.groq.com/openai/v1
```

âš ï¸ Replace with your real Groq key.

---

# ğŸ³ Start Infrastructure

From project root:

```bash
docker compose up -d
```

This starts:

* PostgreSQL
* Supporting services

Wait until containers are healthy.

Check:

```bash
docker ps
```

---

# ğŸ§  Start Backend

```bash
cd archestra/platform/backend
pnpm install
pnpm dev
```

You should see:

```
Server listening at http://127.0.0.1:9000
```

---

# ğŸ¨ Start Frontend

Open new terminal:

```bash
cd archestra/platform/frontend
pnpm install
pnpm dev
```

Open browser:

ğŸ‘‰ [http://127.0.0.1:3000](http://127.0.0.1:3000)

---

# ğŸ”‘ Configure LLM Key in UI

Inside Archestra UI:

1. Go to **Settings â†’ LLM API Keys**
2. Click **Add API Key**
3. Provider: **OpenAI**
4. Paste your Groq key
5. Save
6. Click **Refresh models**

---

# ğŸ¤– Agent Configuration (IMPORTANT)

## Chat Assistant

Set:

* Model: Llama 3.1 8B Instant (or available Groq model)
* API Key: My Groq Key

---

## Hallucination Guard

Set:

* Model: same Groq model
* API Key: My Groq Key

---

## ğŸ”— Link Agents (CRITICAL)

Go to:

Agents â†’ Chat Assistant â†’ Edit

Under **Subagents**:

âœ… Add Hallucination Guard

This enables the multiâ€‘agent flow.

---

# ğŸ§ª Test the System

Open chat and try:

```
The capital of India is Mumbai
```

Expected behavior:

* Chat Assistant generates answer
* Hallucination Guard verifies
* System shows:

  * Accuracy score
  * Risk level
  * Confidence

---

# ğŸ“Š Current Features

* Multiâ€‘agent orchestration
* Groq integration
* Realâ€‘time verification
* Confidence scoring
* Risk classification
* Local fullâ€‘stack deployment

---

# ğŸš§ Known Limitations

* Verification logic is promptâ€‘based (not retrieval grounded)
* No external fact database yet
* UI formatting can be improved
* Kubernetes MCP runtime not configured (safe to ignore locally)

---

# ğŸ”® Future Improvements

* Add web search grounding
* Add citation checking
* Add multiâ€‘tool routing
* Add knowledge graph verification
* Production deployment

---

# ğŸ‘©â€ğŸ’» Team Collaboration Workflow

## For My Teammate

After cloning, they must:

1. Install prerequisites
2. Add their own Groq key in `.env`
3. Run docker compose
4. Start backend
5. Start frontend
6. Configure API key in UI



**You are hackathonâ€‘ready. ğŸš€**
