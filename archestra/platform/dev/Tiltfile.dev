# Development + pre-requisite resources

# MCP Server RBAC resources for local development
# Render from Helm chart and filter to only RBAC resources (avoid duplication)
k8s_yaml(local(
  'helm template archestra-platform ../helm/archestra --namespace default --set archestra.orchestrator.kubernetes.mcpServerRbac.create=true --show-only templates/mcp-serviceaccount.yaml',
  quiet=True
))

k8s_resource(
  new_name='mcp-rbac',
  labels=['dev'],
  objects=[
    'archestra-platform-mcp-k8s-operator:serviceaccount:default',
    'archestra-platform-mcp-server-operator:role:default',
    'archestra-platform-mcp-server-operator:rolebinding:default'
  ]
)

# Define is_prod locally (same logic as main Tiltfile)
is_prod = os.getenv('PROD') == 'true'
dev_resource_name = 'pnpm-prod' if is_prod else 'pnpm-dev'

# Build env dict to sync ARCHESTRA_* to NEXT_PUBLIC_ARCHESTRA_* for frontend
# This is rebuilt on each Tiltfile evaluation (triggered by .env changes)
def get_frontend_env():
  env = {
    # Always disable analytics in local development
    'NEXT_PUBLIC_ARCHESTRA_ANALYTICS': 'disabled',
  }

  # Sync ARCHESTRA_* to NEXT_PUBLIC_ARCHESTRA_* if not already set
  sync_vars = [
    'ARCHESTRA_INTERNAL_API_BASE_URL',
    'ARCHESTRA_API_BASE_URL',
    'ARCHESTRA_SENTRY_ENVIRONMENT',
    'ARCHESTRA_ENTERPRISE_LICENSE_ACTIVATED',
    'ARCHESTRA_AUTH_DISABLE_BASIC_AUTH',
    'ARCHESTRA_AUTH_DISABLE_INVITATIONS',
  ]

  for var in sync_vars:
    value = os.getenv(var)
    next_public_var = 'NEXT_PUBLIC_' + var
    next_public_value = os.getenv(next_public_var)
    # Only sync if ARCHESTRA_* is set and NEXT_PUBLIC_* is not
    if value and value != '' and not next_public_value:
      env[next_public_var] = value

  return env

frontend_env_vars = get_frontend_env()

local_resource(
  'pnpm-install',
  cmd='CI=true pnpm install',
  cmd_bat='set CI=true && pnpm install',
  deps=[
    '../frontend/package.json',
    '../backend/package.json',
  ],
  labels=['dev']
)

# Main dev/prod bundle
if is_prod:
  local_resource(
    dev_resource_name,
    cmd='rm -rf frontend/.next && pnpm build',
    cmd_bat='if exist frontend\\.next rd /s /q frontend\\.next && pnpm build',
    serve_cmd='pnpm start',
    labels=['dev'],
    resource_deps=['db-migrate'],
    env=frontend_env_vars,
    serve_env=frontend_env_vars
  )
else:
  # Backend dev server
  local_resource(
    dev_resource_name + '-backend',
    # Trap ensures all child processes are killed when Tilt stops, preventing orphaned processes from blocking port 3000
    # Uses pkill -P to kill by parent PID since child processes may have their own process groups on macOS
    serve_cmd='trap "pkill -TERM -P $$" EXIT INT TERM; ARCHESTRA_LOGGING_LEVEL=debug pnpm dev --filter @backend & wait $!',
    # On Windows, pnpm dev runs directly; cmd.exe handles process termination when Tilt stops
    serve_cmd_bat='set ARCHESTRA_LOGGING_LEVEL=debug && pnpm dev --filter @backend',
    labels=['dev'],
    resource_deps=['db-migrate'],
    deps=['../.env'],
  )

  # Frontend dev server - waits for backend to be ready
  local_resource(
    dev_resource_name + '-frontend',
    serve_cmd='trap "pkill -TERM -P $$" EXIT INT TERM; pnpm dev --filter @frontend & wait $!',
    serve_cmd_bat='pnpm dev --filter @frontend',
    labels=['dev'],
    resource_deps=[dev_resource_name + '-backend'],
    deps=['../.env'],
    serve_env=frontend_env_vars
  )

local_resource(
  'lint:fix',
  cmd='pnpm type-check && pnpm lint:fix',
  labels=['dev'],
  resource_deps=['pnpm-install'],
  # Disabled auto-watching to prevent spawning processes on every file change
  # Trigger manually with: tilt trigger lint:fix
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

local_resource(
  'lint:fix:unsafe',
  cmd='pnpm lint:fix:unsafe && tilt trigger lint:fix',
  labels=['dev'],
  resource_deps=['pnpm-install'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

# Port-forward for MCP servers using streamable-http transport
# Docker Desktop / kind K8s don't expose NodePorts on localhost, so we use
# kubectl port-forward (which goes through the K8s API server) to make them accessible.
# Discovers MCP server services by label and forwards NodePort -> container port.
# Dead port-forwards are automatically restarted (checked every 5s).
local_resource(
  'mcp-http-port-forward',
  serve_cmd='''
    trap "kill 0" EXIT INT TERM
    echo "Watching for MCP server NodePort services..."
    while true; do
      SERVICES=$(kubectl get svc -l app=mcp-server -n default -o jsonpath='{range .items[*]}{.metadata.name}:{.spec.ports[0].nodePort}:{.spec.ports[0].port} {end}' 2>/dev/null)
      for ENTRY in $SERVICES; do
        SVC_NAME=$(echo "$ENTRY" | cut -d: -f1)
        NODE_PORT=$(echo "$ENTRY" | cut -d: -f2)
        CONTAINER_PORT=$(echo "$ENTRY" | cut -d: -f3)
        if [ "$NODE_PORT" != "null" ] && [ -n "$NODE_PORT" ] && [ -n "$SVC_NAME" ]; then
          if ! lsof -i :"$NODE_PORT" -sTCP:LISTEN >/dev/null 2>&1; then
            # Check that service has ready endpoints before attempting port-forward
            ENDPOINTS=$(kubectl get endpoints "$SVC_NAME" -n default -o jsonpath='{.subsets[0].addresses[0].ip}' 2>/dev/null)
            if [ -n "$ENDPOINTS" ]; then
              echo "Port-forwarding $SVC_NAME: localhost:$NODE_PORT -> $CONTAINER_PORT"
              kubectl port-forward "svc/$SVC_NAME" "$NODE_PORT:$CONTAINER_PORT" -n default &
            fi
          fi
        fi
      done
      sleep 5
    done
  ''',
  labels=['dev'],
)

# Website dev server - manual trigger only
# Website repo is a sibling of the archestra repo (../../website relative to platform/)
website_dir = os.path.join(config.main_dir, '..', '..', 'website', 'app', 'app')
local_resource(
  'website',
  serve_cmd='cd ' + website_dir + ' && pnpm dev',
  labels=['dev'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

# Codegen depends on backend being up (for API schema generation)                                                    
codegen_backend_dep = dev_resource_name if is_prod else dev_resource_name + '-backend' 
local_resource(
  'codegen',
  cmd='pnpm codegen',
  labels=['dev'],
  resource_deps=['pnpm-install', codegen_backend_dep],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)
